{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97027a11",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/alfaizahmed/The reddit climate change (comment).ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alfaizahmed/The%20reddit%20climate%20change%20%28comment%29.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alfaizahmed/The%20reddit%20climate%20change%20%28comment%29.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alfaizahmed/The%20reddit%20climate%20change%20%28comment%29.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c247dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag, bigrams\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import string\n",
    "import numpy as np\n",
    "import time\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from joblib import Parallel, delayed, dump, cpu_count\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf04ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load CSV into DataFrame using pandas\n",
    "df = pd.read_csv('/Users/alfaizahmed/Documents/reddit climate change/the-reddit-climate-change-dataset-comments.csv')\n",
    "\n",
    "\n",
    "dump(df, 'dataframe.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3935d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_remove2 = df.drop(columns=['sentiment', 'type', 'permalink'], inplace=True)\n",
    "col_remove2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916eb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 0.02, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1011598",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0b482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = cpu_count()\n",
    "print(num_cores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66624a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def some_function(i):\n",
    "    return i * i\n",
    "\n",
    "results = Parallel(n_jobs=num_cores)(delayed(some_function)(i) for i in range(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146e3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize VADER sentiment intensity analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def compute_sentiment(text):\n",
    "    return sia.polarity_scores(text)['compound']\n",
    "\n",
    "\n",
    "num_cores = 6\n",
    "\n",
    "# find sentiment scores for each chunk in parallel\n",
    "results = Parallel(n_jobs=num_cores)(\n",
    "    delayed(compute_sentiment)(text) for text in df['body']\n",
    ")\n",
    "\n",
    "df['compound_score'] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e066e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conditions = [\n",
    "    df['compound_score'] > 0.05,\n",
    "    (df['compound_score'] >= -0.05) & (df['compound_score'] <= 0.05),\n",
    "    df['compound_score'] < -0.05\n",
    "]\n",
    "choices = ['positive', 'neutral', 'negative']\n",
    "\n",
    "df['sentiment_label'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b94d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bcff9b5",
   "metadata": {},
   "source": [
    "# PRE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f5f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags and URLs\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove commas and inverted commas\n",
    "    \n",
    "    text = text.replace(',', '').replace('\\'', '').replace('\"', '')\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "     # POS tagging\n",
    "    pos_tags = pos_tag(words)\n",
    "    pos_tags_str = [\"_\".join(tup) for tup in pos_tags]  # combining word and its POS tag\n",
    "\n",
    "\n",
    "    # Remove stopwords and lemmatize the words\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    \n",
    "    \n",
    "    # Create bigrams\n",
    "    bigrams_list = list(bigrams(words))\n",
    "    bigrams_str = [\"_\".join(bigram) for bigram in bigrams_list]  # combining words in bigrams with underscore\n",
    "\n",
    "\n",
    "    # Join the words back into a string\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68848979",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_chunk(chunk):\n",
    "    chunk['body'] = chunk['body'].apply(preprocess_text)\n",
    "    return chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d169d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main(df):\n",
    "    chunksize = 10 ** 4\n",
    "\n",
    "    # Split the DataFrame into chunks\n",
    "    num_chunks = len(df) // chunksize + (1 if len(df) % chunksize else 0)\n",
    "    chunks = np.array_split(df, num_chunks)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Use joblib to parallelize the processing of chunks\n",
    "    processed_chunks = Parallel(n_jobs=6)(delayed(process_chunk)(chunk) for chunk in chunks)\n",
    "    \n",
    "    # Concatenate the processed chunks\n",
    "    processed_df = pd.concat(processed_chunks)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(\"Preprocess took\", end_time - start_time, \"seconds.\")\n",
    "    \n",
    "    \n",
    "    return processed_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d34713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6526128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df = df_processed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation = df_processed.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec54508",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37cbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = prepared_df.isnull().sum()\n",
    "\n",
    "# Check data types\n",
    "data_types = prepared_df.dtypes\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "summary_statistics = prepared_df.describe()\n",
    "\n",
    "missing_values, data_types, summary_statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out the rows with the missing values\n",
    "missing_sentiment_rows = prepared_df[prepared_df['body'].isnull()]\n",
    "missing_sentiment_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e02ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'created_utc' column to a readable datetime format\n",
    "\n",
    "visualisation['created_utc'] = pd.to_datetime(visualisation['created_utc'], unit='s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d640fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f04a74",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7afd6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = prepared_df.groupby('sentiment_label').count()['body'].reset_index().sort_values(by='body', ascending=False)\n",
    "temp.style.background_gradient(cmap='Purples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4bbcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the plotting style and size\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Plotting distribution of sentiment\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(visualisation['compound_score'], bins=50, kde=True)\n",
    "plt.title('Distribution of Sentiment')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3303a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f48ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting distribution of comments over time\n",
    "plt.subplot(2, 2, 3)\n",
    "visualisation.resample('M', on='created_utc').size().plot()\n",
    "plt.title('Number of Comments Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Comments')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb1a429",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the number of comments for each subreddit\n",
    "subreddit_comment_volume = visualisation['subreddit.name'].value_counts().head(10)\n",
    "\n",
    "# Plotting the top 10 subreddits by comment volume\n",
    "plt.figure(figsize=(12, 6))\n",
    "subreddit_comment_volume.plot(kind='bar', color='lightcoral')\n",
    "plt.title('Top 10 Subreddits by Comment Volume')\n",
    "plt.xlabel('Subreddit')\n",
    "plt.ylabel('Number of Comments')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78dfe35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c332c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90260e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce937c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling data to get average sentiment per month\n",
    "avg_sentiment_time = visualisation.resample('M', on='created_utc')['compound_score'].mean()\n",
    "\n",
    "# Plotting the trend\n",
    "plt.figure(figsize=(14, 6))\n",
    "avg_sentiment_time.plot()\n",
    "plt.title('Trend of Average Comment Sentiment Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Sentiment')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252bab00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284452d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d699d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514a3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average sentiment score for the top 10 subreddits\n",
    "subreddit_sentiment = visualisation.groupby('subreddit.name').compound_score.mean()\n",
    "top_subreddits_sentiment = subreddit_sentiment[subreddit_comment_volume.index]\n",
    "\n",
    "# Plotting the average sentiment scores for the top 10 subreddits\n",
    "plt.figure(figsize=(12, 6))\n",
    "top_subreddits_sentiment.plot(kind='bar', color='lightseagreen')\n",
    "plt.title('Average Sentiment Score for Top 10 Subreddits')\n",
    "plt.xlabel('Subreddit')\n",
    "plt.ylabel('Average Sentiment Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb095d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average sentiment and score for NSFW and non-NSFW subreddits\n",
    "nsfw_sentiment = visualisation.groupby('subreddit.nsfw').compound_score.mean()\n",
    "nsfw_score = visualisation.groupby('subreddit.nsfw').score.mean()\n",
    "\n",
    "# Plotting the average sentiment and score for NSFW vs. non-NSFW subreddits\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot for Sentiment\n",
    "nsfw_sentiment.plot(kind='bar', ax=ax1, color=['lightblue', 'lightcoral'])\n",
    "ax1.set_title('Average Sentiment Score by NSFW Category')\n",
    "ax1.set_xlabel('NSFW')\n",
    "ax1.set_ylabel('Average Sentiment Score')\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=0)\n",
    "\n",
    "# Plot for Score\n",
    "nsfw_score.plot(kind='bar', ax=ax2, color=['lightblue', 'lightcoral'])\n",
    "ax2.set_title('Average Comment Score by NSFW Category')\n",
    "ax2.set_xlabel('NSFW')\n",
    "ax2.set_ylabel('Average Comment Score')\n",
    "ax2.set_xticklabels(ax2.get_xticklabels(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b3f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504001d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51c8e57e",
   "metadata": {},
   "source": [
    "# FEATURE EXTRACTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5fdfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer( stop_words='english',max_features= 1000)\n",
    "\n",
    "# Transform the processed_text column into TF-IDF features\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(prepared_df['body'])\n",
    "\n",
    "tfidf_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d51cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = LabelEncoder()\n",
    "encoded_sentiments = encoder.fit_transform(prepared_df['sentiment_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338c40f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate chi-square scores\n",
    "chi2_scores, p_values = chi2(tfidf_features, encoded_sentiments)\n",
    "\n",
    "# Let's select the top 1000 features (or adjust based on your needs)\n",
    "k_best = SelectKBest(chi2, k = 1000)\n",
    "X_chi2_selected = k_best.fit_transform(tfidf_features, encoded_sentiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e390b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638fdc99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec22b445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb219de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97d03eed",
   "metadata": {},
   "source": [
    "# MULTINOMIAL LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516cb31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, encoded_sentiments, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd4459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb60f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs', multi_class='multinomial',max_iter=1000, random_state=42, n_jobs=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f77350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8a4f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3dd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3938773",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy)\n",
    "print(classification_rep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a476d5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .75})\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba893e5",
   "metadata": {},
   "source": [
    "# Hybrid Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f0f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Rule-Based Model using SentiWordNet\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"Map treebank pos tags to WordNet pos tags.\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return wn.NOUN  # Default to noun\n",
    "\n",
    "def sentiwordnet_predict(text):\n",
    "    sentiment = 0.0\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    \n",
    "    for word, tag in tagged:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        synsets = wn.synsets(word, pos=wn_tag)\n",
    "        if not synsets:\n",
    "            continue\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "        sentiment += (swn_synset.pos_score() - swn_synset.neg_score())\n",
    "    \n",
    "    # Return sentiment category\n",
    "    if sentiment > 0:\n",
    "        return 'positive'\n",
    "    elif sentiment < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7cd7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(prepared_df['body'], prepared_df['sentiment_label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(stop_words='english',max_features= 1000)\n",
    "X_train_vec = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_vec = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000, multi_class='multinomial', n_jobs = 6)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "ml_predictions = clf.predict(X_test_vec)\n",
    "\n",
    "# Get predictions from SentiWordNet\n",
    "swn_predictions = [sentiwordnet_predict(text) for text in X_test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27912620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have 3 classes, we'll use a majority vote function for the final predictions\n",
    "def majority_vote(ml_pred, swn_pred):\n",
    "    from collections import Counter\n",
    "    return Counter([ml_pred, swn_pred]).most_common(1)[0][0]\n",
    "\n",
    "final_predictions = [majority_vote(ml, swn) for ml, swn in zip(ml_predictions, swn_predictions)]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0630a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_hybrid = classification_report(y_test, final_predictions)\n",
    "matrix2 = confusion_matrix(y_test,final_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4c3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_hybrid)\n",
    "print(matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c2bb2c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3d735",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(matrix2, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .75})\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23900787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235cda0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bdc64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e752054",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b5ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_features, encoded_sentiments, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b827676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection: Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs= 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27211f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9785f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e86bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "classification_rep_rf = classification_report(y_test, y_pred_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f72bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_rf)\n",
    "print(classification_rep_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f88f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix3 = confusion_matrix(y_test,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408fa97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matrix3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb55ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(matrix3, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .75})\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f305c",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573ff131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the model and parameters\n",
    "mnb = MultinomialNB()\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0]}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GridSearchCV object\n",
    "grid_search_mnb = GridSearchCV(mnb, param_grid, cv=5, n_jobs= 6)\n",
    "grid_search_mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfacf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters and accuracy\n",
    "print('Best parameters for MultinomialNB:', grid_search_mnb.best_params_)\n",
    "print('Best cross-validation score:', grid_search_mnb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "y_pred_mnb = grid_search_mnb.predict(X_test)\n",
    "print('Test accuracy:', accuracy_score(y_test, y_pred_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb282449",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_mnb = classification_report(y_test, y_pred_mnb)\n",
    "matrix4 = confusion_matrix(y_test,y_pred_mnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82959f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_mnb)\n",
    "print(matrix4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd73fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(matrix4, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .75})\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.set_title('Confusion Matrix')\n",
    "\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e095cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c647c186",
   "metadata": {},
   "source": [
    "# Support Vector Machine with Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e2cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6d6dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd104b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0257f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "# Assuming X_train, y_train are your data\n",
    "param_distributions = {\n",
    "    'C': uniform(0.1, 10),\n",
    "    'gamma': reciprocal(0.01, 1),\n",
    "    'kernel': ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea3a853",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    SVC(),\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs= 6,  # Parallel processing\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9daa901",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09633af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fe04fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "y_pred_svm = random_search.predict(X_test)\n",
    "print('Test accuracy:', accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f2ffdd",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18630706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(token)\n",
    "    return result\n",
    "\n",
    "processed_docs = prepared_df['body'].map(preprocess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c74f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a Dictionary & Filter Extremes\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n=100000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b796e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create Bag-of-Words Corpus\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# 4. Train the LDA Model\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                       num_topics=8, \n",
    "                                       id2word=dictionary,                                    \n",
    "                                       passes=10, \n",
    "                                       workers=2)\n",
    "\n",
    "# 5. Display Topics\n",
    "topics = lda_model.print_topics(-1)\n",
    "topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d52f49",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
